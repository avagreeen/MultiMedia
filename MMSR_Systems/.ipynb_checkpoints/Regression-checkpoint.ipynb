{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affective Content Prediction\n",
    "### LIRIS-ACCEDE dataset: original dataset composed of 9800 video clips extracted from 160 movies\n",
    "\n",
    "#### Task 1: Predict the valence and arousal classes of movie clips  \n",
    "valence (negative-neutral-positive)  \n",
    "arousal (calm-neutral-excited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the first part, we use all the features provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colorfulness</th>\n",
       "      <th>alpha</th>\n",
       "      <th>hueCount</th>\n",
       "      <th>maxSaliencyCount</th>\n",
       "      <th>compositionalBalance</th>\n",
       "      <th>depthOfField</th>\n",
       "      <th>saliencyDisparity</th>\n",
       "      <th>spatialEdgeDistributionArea</th>\n",
       "      <th>entropyComplexity</th>\n",
       "      <th>nbWhiteFrames</th>\n",
       "      <th>nbFades</th>\n",
       "      <th>nbSceneCuts</th>\n",
       "      <th>asymmetry_env</th>\n",
       "      <th>flatness</th>\n",
       "      <th>zcr</th>\n",
       "      <th>colorStrength</th>\n",
       "      <th>colorRawEnergy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACCEDE00000</th>\n",
       "      <td>47.939117</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>4.59312</td>\n",
       "      <td>110.988586</td>\n",
       "      <td>0.015579</td>\n",
       "      <td>0.842532</td>\n",
       "      <td>12.011075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.727504</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.319205</td>\n",
       "      <td>0.113005</td>\n",
       "      <td>162.118626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACCEDE00001</th>\n",
       "      <td>52.748894</td>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>1.085655</td>\n",
       "      <td>125.017303</td>\n",
       "      <td>0.022905</td>\n",
       "      <td>0.860802</td>\n",
       "      <td>12.795528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57.945141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.194707</td>\n",
       "      <td>0.072096</td>\n",
       "      <td>11.467636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            colorfulness alpha hueCount maxSaliencyCount compositionalBalance  \\\n",
       "ACCEDE00000    47.939117     5      100         0.002094              4.59312   \n",
       "ACCEDE00001    52.748894    41       45         0.004708             1.085655   \n",
       "\n",
       "            depthOfField saliencyDisparity spatialEdgeDistributionArea  \\\n",
       "ACCEDE00000   110.988586          0.015579                    0.842532   \n",
       "ACCEDE00001   125.017303          0.022905                    0.860802   \n",
       "\n",
       "            entropyComplexity nbWhiteFrames nbFades nbSceneCuts asymmetry_env  \\\n",
       "ACCEDE00000         12.011075             0       0           1     19.727504   \n",
       "ACCEDE00001         12.795528             0       0           1     57.945141   \n",
       "\n",
       "             flatness       zcr colorStrength colorRawEnergy  \n",
       "ACCEDE00000  0.000287  0.319205      0.113005     162.118626  \n",
       "ACCEDE00001         0  0.194707      0.072096      11.467636  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the features of arousal\n",
    "with open('features/ACCEDEfeaturesArousal_TAC2015.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    data = [line.replace('\\n','').split('\\t') for line in lines]\n",
    "    \n",
    "# make a dataframe from it\n",
    "a = np.asarray(data)\n",
    "index = a[1:,1]\n",
    "col = a[0,:]\n",
    "a = a[1:,:]\n",
    "df_arousal = pd.DataFrame(data=a, index=index, columns=col).drop(['id','name'],axis=1)\n",
    "\n",
    "# read in the features of arousal\n",
    "with open('features/ACCEDEfeaturesValence_TAC2015.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    data = [line.replace('\\n','').split('\\t') for line in lines]\n",
    "    \n",
    "# make a dataframe from it\n",
    "a = np.asarray(data)\n",
    "index = a[1:,1]\n",
    "col = a[0,:]\n",
    "a = a[1:,:]\n",
    "df_valence = pd.DataFrame(data=a, index=index, columns=col).drop(['id','name'],axis=1)\n",
    "df_valence.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     3552\n",
      "-1    3411\n",
      "1     2837\n",
      "Name: valenceClass, dtype: int64\n",
      "-1    6206\n",
      "1     2247\n",
      "0     1347\n",
      "Name: arousalClass, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# read the annotation\n",
    "with open('annotations/ACCEDEaffect.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    annotate = [line.replace('\\n','').split('\\t') for line in lines]\n",
    "b = np.asarray(annotate)\n",
    "index = b[1:,1]\n",
    "col = b[0,:]\n",
    "b = b[1:,:]\n",
    "df_annotate = pd.DataFrame(data=b, index=index, columns=col).drop(['id','name'],axis=1)\n",
    "\n",
    "## Examine the class distribution\n",
    "print (df_annotate['valenceClass'].value_counts())\n",
    "print (df_annotate['arousalClass'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the sets (train:1, test:0, validation:2)\n",
    "with open('annotations/ACCEDEsets.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    annotate = [line.replace('\\n','').split('\\t') for line in lines]\n",
    "b = np.asarray(annotate)\n",
    "index = b[1:,1]\n",
    "col = b[0,:]\n",
    "b = b[1:,:]\n",
    "df_set = pd.DataFrame(data=b, index=index, columns=col).drop(['id','name'],axis=1)\n",
    "df_set['set'] = df_set['set'].astype(int)\n",
    "\n",
    "valence = pd.concat([df_valence, df_annotate['valenceClass'].astype(int), df_set['set']], axis=1)\n",
    "arousal = pd.concat([df_arousal, df_annotate['arousalClass'].astype(int), df_set['set']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colorfulness                   object\n",
       "alpha                          object\n",
       "hueCount                       object\n",
       "maxSaliencyCount               object\n",
       "compositionalBalance           object\n",
       "depthOfField                   object\n",
       "saliencyDisparity              object\n",
       "spatialEdgeDistributionArea    object\n",
       "entropyComplexity              object\n",
       "nbWhiteFrames                  object\n",
       "nbFades                        object\n",
       "nbSceneCuts                    object\n",
       "asymmetry_env                  object\n",
       "flatness                       object\n",
       "zcr                            object\n",
       "colorStrength                  object\n",
       "colorRawEnergy                 object\n",
       "valenceClass                    int32\n",
       "set                             int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valence.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "Valence: (2450, 19)   Arousal: (2450, 25)\n"
     ]
    }
   ],
   "source": [
    "#split training and testing set\n",
    "trainV = valence.loc[valence['set']==1] \n",
    "trainA = arousal.loc[arousal['set']==1] \n",
    "testV = valence.loc[valence['set']==0] \n",
    "testA = arousal.loc[arousal['set']==0] \n",
    "valV = valence.loc[valence['set']==2] \n",
    "valA = arousal.loc[arousal['set']==2] \n",
    "print('Train Set')\n",
    "print('Valence:', trainV.shape, '  Arousal:',trainA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_feature = ['colorfulness','minEnergy','alpha','lightning','globalActivity'\n",
    "                            ,'nbWhiteFrames','nbSceneCuts','cutLength','flatness_env'\n",
    "                            ,'wtf_max2stdratio_1','wtf_max2stdratio_2','wtf_max2stdratio_3'\n",
    "                            ,'wtf_max2stdratio_4','wtf_max2stdratio_5','wtf_max2stdratio_6'\n",
    "                            ,'wtf_max2stdratio_7','wtf_max2stdratio_8','wtf_max2stdratio_9'\n",
    "                            ,'wtf_max2stdratio_10','wtf_max2stdratio_11','wtf_max2stdratio_12'\n",
    "                            ,'medianLightness','slope']\n",
    "valence_feature = ['colorfulness','alpha','hueCount','maxSaliencyCount','compositionalBalance'\n",
    "                                       ,'depthOfField','saliencyDisparity','spatialEdgeDistributionArea'\n",
    "                                       ,'entropyComplexity','nbWhiteFrames','nbFades','nbSceneCuts','asymmetry_env'\n",
    "                                       ,'flatness','zcr','colorStrength','colorRawEnergy']\n",
    "\n",
    "train_arousal = np.asarray(trainA[arousal_feature]).astype(float)\n",
    "train_valence = np.asarray(trainV[valence_feature]).astype(float)\n",
    "test_arousal = np.asarray(testA[arousal_feature]).astype(float)\n",
    "test_valence = np.asarray(testV[valence_feature]).astype(float)\n",
    "val_arousal = np.asarray(valA[arousal_feature]).astype(float)\n",
    "val_valence = np.asarray(valV[valence_feature]).astype(float)\n",
    "\n",
    "label_trn = np.vstack( (trainV['valenceClass'].values,trainA['arousalClass'].values))\n",
    "label_tst = np.vstack( (testV['valenceClass'].values, testA['arousalClass'].values))\n",
    "label_val = np.vstack( (valV['valenceClass'].values, valA['arousalClass'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalerA = StandardScaler().fit(train_arousal)\n",
    "X_train_a = scalerA.transform(train_arousal)\n",
    "X_test_a = scalerA.transform(test_arousal)\n",
    "X_val_a = scalerA.transform(val_arousal)\n",
    "\n",
    "scalerV = StandardScaler().fit(train_valence)\n",
    "X_train_v = scalerV.transform(train_valence)\n",
    "X_test_v = scalerV.transform(test_valence)\n",
    "X_val_v = scalerV.transform(val_valence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate to treat training and validation set as a total training set when testing\n",
    "X_total_v = np.vstack((X_train_v, X_val_v))\n",
    "X_total_a = np.vstack((X_train_a, X_val_a))\n",
    "label_total= np.hstack((label_trn, label_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## Valence Prediction ####################\n",
      "RF(10) accuracy: 0.352245\n",
      "RF(20) accuracy: 0.375102\n",
      "RF(30) accuracy: 0.366122\n",
      "RF(40) accuracy: 0.373061\n",
      "RF(50) accuracy: 0.355918\n",
      "RF(60) accuracy: 0.363265\n",
      "RF(70) accuracy: 0.366939\n",
      "RF(80) accuracy: 0.366939\n",
      "RF(90) accuracy: 0.365306\n",
      "[TESTING] RF (20) accuracy: 0.403469\n",
      "KNN(3) accuracy: 0.337551\n",
      "KNN(5) accuracy: 0.354286\n",
      "KNN(7) accuracy: 0.362041\n",
      "[TESTING] KNN (7) accuracy: 0.380000\n",
      "[TESTING] LR accuracy: 0.429184\n",
      "############## Arousal Prediction ####################\n",
      "RF(10) accuracy: 0.597959\n",
      "RF(20) accuracy: 0.621633\n",
      "RF(30) accuracy: 0.618367\n",
      "RF(40) accuracy: 0.631020\n",
      "RF(50) accuracy: 0.629796\n",
      "RF(60) accuracy: 0.630612\n",
      "RF(70) accuracy: 0.631429\n",
      "RF(80) accuracy: 0.635102\n",
      "RF(90) accuracy: 0.632245\n",
      "[TESTING] RF (80) accuracy: 0.645102\n",
      "KNN(3) accuracy: 0.580408\n",
      "KNN(5) accuracy: 0.611429\n",
      "KNN(7) accuracy: 0.611837\n",
      "[TESTING] KNN (7) accuracy: 0.609592\n",
      "[TESTING] LR accuracy: 0.636122\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def findAcc(p,y):\n",
    "    return len(np.where((p - y) == 0)[0]) / float(len(p))\n",
    "\n",
    "lr = linear_model.LogisticRegression()\n",
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        print('############## Valence Prediction ####################')\n",
    "        trnX = X_train_v\n",
    "        valX = X_val_v\n",
    "        tstX = X_test_v\n",
    "        totalX = X_total_v\n",
    "    else:\n",
    "        print('############## Arousal Prediction ####################')\n",
    "        trnX = X_train_a\n",
    "        valX = X_val_a\n",
    "        tstX = X_test_a\n",
    "        totalX = X_total_a\n",
    "        \n",
    "    trnY = label_trn[i]\n",
    "    tstY = label_tst[i]\n",
    "    valY = label_val[i]\n",
    "    totalY = label_total[i]\n",
    "    \n",
    "    ############## Random Forest Classifier ###########\n",
    "    # choose param\n",
    "    bestNum = 0\n",
    "    bestAcc = 0\n",
    "    for tree in range(10,100,10):\n",
    "        rf = RandomForestClassifier(n_estimators = tree)\n",
    "        rf.fit(trnX, trnY)\n",
    "        pred = rf.predict(valX)\n",
    "        acc = findAcc(pred, valY)\n",
    "        print('RF(%i) accuracy: %f' %(tree,acc))\n",
    "        if acc>bestAcc:\n",
    "            bestAcc = acc\n",
    "            bestNum = tree\n",
    "    \n",
    "    # test\n",
    "    final_rf = RandomForestClassifier(n_estimators = bestNum)\n",
    "    final_rf.fit(totalX, totalY)\n",
    "    pred = final_rf.predict(tstX)\n",
    "    acc = findAcc(pred, tstY)\n",
    "    con_rf = confusion_matrix(tstY, pred)\n",
    "    print('[TESTING] RF (%i) accuracy: %f' %(bestNum, acc))\n",
    "        \n",
    "    ############## KNN Classifier ###########\n",
    "    # choose param\n",
    "    bestNum = 0\n",
    "    bestAcc = 0\n",
    "    for neighbor in range(3,9,2):\n",
    "        knn = KNeighborsClassifier(n_neighbors=neighbor)\n",
    "        knn.fit(trnX, trnY)\n",
    "        pred = knn.predict(valX)\n",
    "        acc = findAcc(pred, valY)\n",
    "        print('KNN(%i) accuracy: %f' %(neighbor,acc))\n",
    "        if acc>bestAcc:\n",
    "            bestAcc = acc\n",
    "            bestNum = neighbor\n",
    "    \n",
    "    # test\n",
    "    final_knn = KNeighborsClassifier(n_neighbors=bestNum)\n",
    "    final_knn.fit(totalX, totalY)\n",
    "    pred = final_knn.predict(tstX)\n",
    "    acc = findAcc(pred, tstY)\n",
    "    print('[TESTING] KNN (%i) accuracy: %f' %(bestNum, acc))\n",
    "    con_knn = confusion_matrix(tstY, pred)\n",
    "        \n",
    "    ############# Logistic Regression #############\n",
    "    lr.fit(totalX, totalY)\n",
    "    pred = lr.predict(tstX)\n",
    "    acc = findAcc(pred, tstY)\n",
    "    print('[TESTING] LR accuracy: %f' %(acc))\n",
    "    con_lr = confusion_matrix(tstY, pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now add audio features that we extracted by ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file and parse\n",
    "with open('features/Output.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    f = [line.replace(' ','').split(',') for line in lines]\n",
    "\n",
    "col = f[0]\n",
    "f_array = np.asarray(f)\n",
    "# delete some weird rows\n",
    "ff = np.delete(f_array, 1474, 0)\n",
    "ff = np.delete(ff,5515,0)\n",
    "index = ff[1:,0]\n",
    "audio = pd.DataFrame(data=ff[1:,0:7], index = index, columns = col[0:7]).drop('audioID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the dataframes\n",
    "df_valence_audio = pd.merge(df_valence, audio, left_index=True, right_index=True)\n",
    "df_arousal_audio = pd.merge(df_arousal, audio, left_index=True, right_index=True)\n",
    "valence_audio = pd.concat([df_valence_audio, df_annotate['valenceClass'].astype(int), df_set['set']], axis=1)\n",
    "arousal_audio = pd.concat([df_arousal_audio, df_annotate['arousalClass'].astype(int), df_set['set']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "Valence: (2450, 25)   Arousal: (2450, 31)\n"
     ]
    }
   ],
   "source": [
    "### Use the same ML flow as above\n",
    "#split training and testing set\n",
    "trainV = valence_audio.loc[valence_audio['set']==1] \n",
    "trainA = arousal_audio.loc[arousal_audio['set']==1] \n",
    "testV = valence_audio.loc[valence_audio['set']==0] \n",
    "testA = arousal_audio.loc[arousal_audio['set']==0] \n",
    "valV = valence_audio.loc[valence_audio['set']==2] \n",
    "valA = arousal_audio.loc[arousal_audio['set']==2] \n",
    "\n",
    "print('Train Set')\n",
    "print('Valence:', trainV.shape, '  Arousal:',trainA.shape)\n",
    "\n",
    "train_arousal = np.asarray(trainA).astype(float)\n",
    "train_valence = np.asarray(trainV).astype(float)\n",
    "test_arousal = np.asarray(testA).astype(float)\n",
    "test_valence = np.asarray(testV).astype(float)\n",
    "val_arousal = np.asarray(valA).astype(float)\n",
    "val_valence = np.asarray(valV).astype(float)\n",
    "\n",
    "label_trn = np.vstack( (trainV['valenceClass'].values, trainA['arousalClass'].values))\n",
    "label_tst = np.vstack( (testV['valenceClass'].values, testA['arousalClass'].values))\n",
    "label_val = np.vstack( (valV['valenceClass'].values, valA['arousalClass'].values))\n",
    "\n",
    "# normalize the data\n",
    "scalerA = StandardScaler().fit(train_arousal)\n",
    "X_train_a = scalerA.transform(train_arousal)\n",
    "X_test_a = scalerA.transform(test_arousal)\n",
    "X_val_a = scalerA.transform(val_arousal)\n",
    "\n",
    "scalerV = StandardScaler().fit(train_valence)\n",
    "X_train_v = scalerV.transform(train_valence)\n",
    "X_test_v = scalerV.transform(test_valence)\n",
    "X_val_v = scalerV.transform(val_valence)\n",
    "\n",
    "X_total_v = np.vstack((X_train_v, X_val_v))\n",
    "X_total_a = np.vstack((X_train_a, X_val_a))\n",
    "label_total= np.hstack((label_trn, label_val ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## Valence Prediction ####################\n",
      "RF(10) accuracy: 0.998776\n",
      "RF(20) accuracy: 1.000000\n",
      "RF(30) accuracy: 1.000000\n",
      "RF(40) accuracy: 1.000000\n",
      "RF(50) accuracy: 1.000000\n",
      "RF(60) accuracy: 1.000000\n",
      "RF(70) accuracy: 1.000000\n",
      "RF(80) accuracy: 1.000000\n",
      "RF(90) accuracy: 1.000000\n",
      "[TESTING] RF (20) accuracy: 1.000000\n",
      "KNN(3) accuracy: 0.757959\n",
      "KNN(5) accuracy: 0.790204\n",
      "KNN(7) accuracy: 0.812653\n",
      "[TESTING] KNN (7) accuracy: 0.850000\n",
      "[TESTING] LR accuracy: 1.000000\n",
      "############## Arousal Prediction ####################\n",
      "RF(10) accuracy: 0.994694\n",
      "RF(20) accuracy: 0.998367\n",
      "RF(30) accuracy: 1.000000\n",
      "RF(40) accuracy: 0.999592\n",
      "RF(50) accuracy: 1.000000\n",
      "RF(60) accuracy: 1.000000\n",
      "RF(70) accuracy: 1.000000\n",
      "RF(80) accuracy: 1.000000\n",
      "RF(90) accuracy: 1.000000\n",
      "[TESTING] RF (30) accuracy: 0.999796\n",
      "KNN(3) accuracy: 0.808571\n",
      "KNN(5) accuracy: 0.815102\n",
      "KNN(7) accuracy: 0.819592\n",
      "[TESTING] KNN (7) accuracy: 0.858367\n",
      "[TESTING] LR accuracy: 0.636122\n"
     ]
    }
   ],
   "source": [
    "lr = linear_model.LogisticRegression()\n",
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        print('############## Valence Prediction ####################')\n",
    "        trnX = X_train_v\n",
    "        valX = X_val_v\n",
    "        tstX = X_test_v\n",
    "        totalX = X_total_v\n",
    "    else:\n",
    "        print('############## Arousal Prediction ####################')\n",
    "        trnX = X_train_a\n",
    "        valX = X_val_a\n",
    "        tstX = X_test_a\n",
    "        totalX = X_total_a\n",
    "        \n",
    "    trnY = label_trn[i]\n",
    "    tstY = label_tst[i]\n",
    "    valY = label_val[i]\n",
    "    totalY = label_total[i]\n",
    "    \n",
    "    ############## Random Forest Classifier ###########\n",
    "    # choose param\n",
    "    bestNum = 0\n",
    "    bestAcc = 0\n",
    "    for tree in range(10,100,10):\n",
    "        rf = RandomForestClassifier(n_estimators = tree)\n",
    "        rf.fit(trnX, trnY)\n",
    "        pred = rf.predict(valX)\n",
    "        acc = findAcc(pred, valY)\n",
    "        print('RF(%i) accuracy: %f' %(tree,acc))\n",
    "        if acc>bestAcc:\n",
    "            bestAcc = acc\n",
    "            bestNum = tree\n",
    "    \n",
    "    # test\n",
    "    final_rf = RandomForestClassifier(n_estimators = bestNum)\n",
    "    final_rf.fit(totalX, totalY)\n",
    "    pred = final_rf.predict(tstX)\n",
    "    acc = findAcc(pred, tstY)\n",
    "    con_rf = confusion_matrix(tstY, pred)\n",
    "    print('[TESTING] RF (%i) accuracy: %f' %(bestNum, acc))\n",
    "        \n",
    "    ############## KNN Classifier ###########\n",
    "    # choose param\n",
    "    bestNum = 0\n",
    "    bestAcc = 0\n",
    "    for neighbor in range(3,9,2):\n",
    "        knn = KNeighborsClassifier(n_neighbors=neighbor)\n",
    "        knn.fit(trnX, trnY)\n",
    "        pred = knn.predict(valX)\n",
    "        acc = findAcc(pred, valY)\n",
    "        print('KNN(%i) accuracy: %f' %(neighbor,acc))\n",
    "        if acc>bestAcc:\n",
    "            bestAcc = acc\n",
    "            bestNum = neighbor\n",
    "    \n",
    "    # test\n",
    "    final_knn = KNeighborsClassifier(n_neighbors=bestNum)\n",
    "    final_knn.fit(totalX, totalY)\n",
    "    pred = final_knn.predict(tstX)\n",
    "    acc = findAcc(pred, tstY)\n",
    "    print('[TESTING] KNN (%i) accuracy: %f' %(bestNum, acc))\n",
    "    con_knn = confusion_matrix(tstY, pred)\n",
    "        \n",
    "    ############# Logistic Regression #############\n",
    "    lr.fit(totalX, totalY)\n",
    "    pred = lr.predict(tstX)\n",
    "    acc = findAcc(pred, tstY)\n",
    "    print('[TESTING] LR accuracy: %f' %(acc))\n",
    "    con_lr = confusion_matrix(tstY, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
